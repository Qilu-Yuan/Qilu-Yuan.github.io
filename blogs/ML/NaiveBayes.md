---
layout: page
permalink: /blogs/ML/NaiveBayes/index.html
title: 朴素贝叶斯方法
---

## 朴素贝叶斯方法

### 1.基本思路

<br>

用于解决分类问题，即将连续取值的输入映射为离散取值的输出，算法的名字叫作“**朴素贝叶斯方法**”。<br>

**其基本思想在于分析待分类样本出现在每个输出类别中的后验概率，并以取得最大后验概率的类别作为分类的输出**。<br>

假设训练数据的属性由 $n$ 维随机向量 表示，其分类结果用随机变量 $y$ 表示，那么 $x$ 和 $y$的统计规律就可以用联合概率分布 描述，每一个具体的样本 都可以通过独立同分布地产生。<br>

朴素贝叶斯分类器的出发点就是这个联合概率分布，根据条件概率的性质可以得到<br>

$$
P(X,Y) = P(Y) P(X|Y) = P(X)P(Y|X)
$$
<br>

在上式中，$P(Y)$ 代表着每个类别出现的概率，也就是**类先验概率**；$P(X \vert Y)$ 代表着在给定的类别下不同属性出现的概率，也就是**类似然概率**。<br>

### 2.独立性假设

先验概率容易根据训练数据计算出来，只需要统计不同类别样本的数目即可。**而似然概率受属性取值数目的影响，其估计较为困难**。如果每个样本包含 100 个属性，每个属性的取值都可能有 100 种，那么对分类的每个结果，要计算的条件概率数目就是 $100^2=10000$,对似然概率的精确估计就需要庞大的数据量。<br>

**条件独立性假设保证了所有属性相互独立，互不影响，每个属性独立地对分类结果发生作用**。**这样类条件概率就变成了属性条件概率的乘积**。<br>

$$
P(X=x|Y=c) = P(X^{(1)}=x^{(1)},X^{(2)}=x^{(2)},...,X^{(n)} = x^{(n)}|Y=c) \\ = \Pi_{j=1} P(X^{(j)} = x^{(j)}|Y=c)
$$
<br>

**这正是朴素贝叶斯方法的“朴素”之处，通过必要的假设来简化计算，并回归问题的本质**。<br>

没有这一假设时，每个样本的分类结果 y 只能刻画其所有属性$(x_1,x_2,...,x_n)$ 形成的整体,有了条件独立性假设后，分类结果 $y$ 就相当于实现了 $n$ 重复用.<br>

然而**属性的条件独立性假设是个相当强的假设**，属性条件独立性假设会导致数据的过度简化，因而会给分类性能带来些许影响。但它带来的数学上的便利却能极大简化分类问题的计算复杂度，性能上的部分折中也就并非不可接受。<br>

### 3.求解流程

有了训练数据集，先验概率 $P(Y)$ 和似然概率 $P(XY)$ 就可以视为已知条件，用来求解后验概率 $P(Y \vert X)$。对于给定的输入 $x$，朴素贝叶斯分类器利用贝叶斯定理求解后验概率，并将后验概率最大的类作为输出。<br>

**从模型最优化的角度观察，朴素贝叶斯分类器是平均意义上预测能力最优的模型，也就是使期望风险最小化**。期望风险是风险函数的数学期望，度量的是平均意义下模型预测的误差特性，可以视为单次预测误差在联合概率分布 $P(X, Y)$ 上的数学期望。<br>

由于训练数据集规模有限，某些属性值可能从未与某个类同时出现，导致属性条件概率为0，这会使朴素贝叶斯分类产生错误结论。为避免未出现属性值干扰分类信息，需要在计算属性条件概率时添加“**拉普拉斯平滑**”。拉普拉斯平滑是在计算类先验概率和属性条件概率时，在分子上添加一个小的修正量，而在分母上则添加该修正量与分类数的乘积。这可以避免零概率对分类结果的影响，并在训练集数据量较大时使修正量对先验概率的影响可忽略不计。<br>

实际上，朴素贝叶斯是一种高效的方法。以分类的正确性作为误差指标时，只要能够找到最大的后验概率，就意味着实现了正确分类。找到的后验概率估计值的精确性则相对不那么重要。<br>

朴素贝叶斯分类受属性间依赖关系在不同类别上的分布影响，而不仅仅是依赖关系本身。尽管如此，属性条件独立性假设仍会影响分类性能。为此，研究人员提出了**“半朴素贝叶斯分类器”**，考虑部分属性间的依赖关系，保留强相关性而无需计算复杂的联合概率分布。常见方法是建立独依赖关系，假设每个属性最多只依赖一个其他属性，从而衍生出多种独依赖分类器。<br>

#### 应用

朴素贝叶斯分类器应用广泛，如垃圾邮件分类和社交网络用户判断。在信息检索领域尤其实用。总之，贝叶斯分类方法的策略是根据训练数据计算后验概率，并基于此选择最佳决策。<br>

#### 总结

朴素贝叶斯方法利用后验概率选择最佳分类，后验概率可以通过贝叶斯定理求解；<br>

朴素贝叶斯方法假定所有属性相互独立，基于这一假设将类条件概率转化为属性条件概率的乘积；<br>

朴素贝叶斯方法可以使期望风险最小化；<br>

影响朴素贝叶斯分类的是所有属性之间的依赖关系在不同类别上的分布。<br>